{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises: Day 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [404]>\n",
      "404\n",
      "{'date': 'Wed, 27 Dec 2023 15:44:26 GMT', 'server': 'Apache', 'last-modified': 'Mon, 01 May 2023 17:35:22 GMT', 'accept-ranges': 'bytes', 'content-length': '6392', 'content-type': 'text/html'}\n",
      "[(23, 'lia'), (17, 'a'), (14, 'li'), (13, 'meta'), (13, 'div'), (10, 'ul'), (9, 'input'), (7, 'link'), (5, 'Gutenberg'), (5, 'of')]\n"
     ]
    }
   ],
   "source": [
    "# Read this url and find the 10 most frequent words. romeo_and_juliet = 'http://www.gutenberg.org/files/1112/1112.txt'\n",
    "\n",
    "import re\n",
    "import requests\n",
    "url = 'http://www.gutenberg.org/files/1112/1112.txt'\n",
    "response = requests.get(url)\n",
    "print(response)\n",
    "print(response.status_code)\n",
    "print(response.headers)\n",
    "text = response.text\n",
    "text = re.sub(r'[^\\w\\s]','',text)\n",
    "words = text.split()\n",
    "words_dict = {}\n",
    "for word in words:\n",
    "    words_dict[word] = words_dict.get(word,0) + 1\n",
    "words_sorted = sorted(words_dict.items(),key=lambda x:x[1],reverse=True)\n",
    "result = [(word[1],word[0]) for word in words_sorted]\n",
    "print(result[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight Statistics:\n",
      "Min: 2.0 kg\n",
      "Max: 5.0 kg\n",
      "Mean: 3.2238805970149254 kg\n",
      "Median: 3.0 kg\n",
      "Standard Deviation: 0.8845628182703051 kg\n",
      "\n",
      "Lifespan Statistics:\n",
      "No lifespan data available\n",
      "No lifespan data available\n",
      "No lifespan data available\n",
      "No lifespan data available\n",
      "No lifespan data available\n",
      "\n",
      "Frequency Table of Country and Breed:\n",
      "Egypt:\n",
      "  Abyssinian: 1\n",
      "  Chausie: 1\n",
      "  Egyptian Mau: 1\n",
      "\n",
      "Greece:\n",
      "  Aegean: 1\n",
      "\n",
      "United States:\n",
      "  American Bobtail: 1\n",
      "  American Curl: 1\n",
      "  American Shorthair: 1\n",
      "  American Wirehair: 1\n",
      "  Balinese: 1\n",
      "  Bambino: 1\n",
      "  Bengal: 1\n",
      "  Bombay: 1\n",
      "  California Spangled: 1\n",
      "  Chantilly-Tiffany: 1\n",
      "  Cheetoh: 1\n",
      "  Colorpoint Shorthair: 1\n",
      "  Exotic Shorthair: 1\n",
      "  Himalayan: 1\n",
      "  Javanese: 1\n",
      "  Maine Coon: 1\n",
      "  Munchkin: 1\n",
      "  Nebelung: 1\n",
      "  Ocicat: 1\n",
      "  Oriental: 1\n",
      "  Pixie-bob: 1\n",
      "  Ragamuffin: 1\n",
      "  Ragdoll: 1\n",
      "  Savannah: 1\n",
      "  Selkirk Rex: 1\n",
      "  Snowshoe: 1\n",
      "  Toyger: 1\n",
      "  York Chocolate: 1\n",
      "\n",
      "United Arab Emirates:\n",
      "  Arabian Mau: 1\n",
      "\n",
      "Australia:\n",
      "  Australian Mist: 1\n",
      "\n",
      "France:\n",
      "  Birman: 1\n",
      "  Chartreux: 1\n",
      "\n",
      "United Kingdom:\n",
      "  British Longhair: 1\n",
      "  British Shorthair: 1\n",
      "  Burmilla: 1\n",
      "  Cornish Rex: 1\n",
      "  Devon Rex: 1\n",
      "  Havana Brown: 1\n",
      "  Malayan: 1\n",
      "  Scottish Fold: 1\n",
      "\n",
      "Burma:\n",
      "  Burmese: 1\n",
      "  European Burmese: 1\n",
      "\n",
      "Canada:\n",
      "  Cymric: 1\n",
      "  Sphynx: 1\n",
      "  Tonkinese: 1\n",
      "\n",
      "Cyprus:\n",
      "  Cyprus: 1\n",
      "\n",
      "Russia:\n",
      "  Donskoy: 1\n",
      "  Kurilian: 1\n",
      "  Russian Blue: 1\n",
      "  Siberian: 1\n",
      "\n",
      "China:\n",
      "  Dragon Li: 1\n",
      "\n",
      "Japan:\n",
      "  Japanese Bobtail: 1\n",
      "\n",
      "Thailand:\n",
      "  Khao Manee: 1\n",
      "  Korat: 1\n",
      "  LaPerm: 1\n",
      "  Siamese: 1\n",
      "\n",
      "Isle of Man:\n",
      "  Manx: 1\n",
      "\n",
      "Norway:\n",
      "  Norwegian Forest Cat: 1\n",
      "\n",
      "Iran (Persia):\n",
      "  Persian: 1\n",
      "\n",
      "Singapore:\n",
      "  Singapura: 1\n",
      "\n",
      "Somalia:\n",
      "  Somali: 1\n",
      "\n",
      "Turkey:\n",
      "  Turkish Angora: 1\n",
      "  Turkish Van: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read the cats API and cats_api = 'https://api.thecatapi.com/v1/breeds' and find :\n",
    "# the min, max, mean, median, standard deviation of cats' weight in metric units.\n",
    "# the min, max, mean, median, standard deviation of cats' lifespan in years.\n",
    "# Create a frequency table of country and breed of cats\n",
    "\n",
    "\n",
    "import requests\n",
    "import statistics\n",
    "\n",
    "cats_api = 'https://api.thecatapi.com/v1/breeds'\n",
    "\n",
    "# Fetch data from the Cat API\n",
    "response = requests.get(cats_api)\n",
    "breeds_data = response.json()\n",
    "\n",
    "# Extract weight and lifespan data\n",
    "weights = [breed['weight']['metric'] if 'weight' in breed else None for breed in breeds_data]\n",
    "lifespans = [breed['life_span'] if 'life_span' in breed else None for breed in breeds_data]\n",
    "\n",
    "# Convert weight data to numeric values, handling None values\n",
    "weights_numeric = [float(weight.split()[0]) if weight is not None else None for weight in weights]\n",
    "\n",
    "# Convert lifespan data to numeric values, handling None values\n",
    "lifespans_numeric = [float(lifespan.split()[0]) if lifespan and lifespan.isdigit() else None for lifespan in lifespans]\n",
    "\n",
    "# Remove None values from lifespans_numeric\n",
    "lifespans_numeric = [value for value in lifespans_numeric if value is not None]\n",
    "\n",
    "# Calculate statistics for weight\n",
    "weight_min = min(weights_numeric) if any(weights_numeric) else None\n",
    "weight_max = max(weights_numeric) if any(weights_numeric) else None\n",
    "weight_mean = statistics.mean(weights_numeric) if any(weights_numeric) else None\n",
    "weight_median = statistics.median(weights_numeric) if any(weights_numeric) else None\n",
    "weight_std_dev = statistics.stdev(weights_numeric) if any(weights_numeric) else None\n",
    "\n",
    "# Calculate statistics for lifespan\n",
    "lifespan_min = min(lifespans_numeric) if any(lifespans_numeric) else None\n",
    "lifespan_max = max(lifespans_numeric) if any(lifespans_numeric) else None\n",
    "lifespan_mean = statistics.mean(lifespans_numeric) if any(lifespans_numeric) else None\n",
    "lifespan_median = statistics.median(lifespans_numeric) if any(lifespans_numeric) else None\n",
    "lifespan_std_dev = statistics.stdev(lifespans_numeric) if any(lifespans_numeric) else None\n",
    "\n",
    "# Create a frequency table of country and breed\n",
    "frequency_table = {}\n",
    "for breed in breeds_data:\n",
    "    country = breed.get('origin', 'Unknown')\n",
    "    breed_name = breed.get('name', 'Unknown')\n",
    "    \n",
    "    if country not in frequency_table:\n",
    "        frequency_table[country] = {}\n",
    "    \n",
    "    if breed_name not in frequency_table[country]:\n",
    "        frequency_table[country][breed_name] = 1\n",
    "    else:\n",
    "        frequency_table[country][breed_name] += 1\n",
    "\n",
    "# Print the results\n",
    "print(\"Weight Statistics:\")\n",
    "print(f\"Min: {weight_min} kg\" if weight_min is not None else \"No weight data available\")\n",
    "print(f\"Max: {weight_max} kg\" if weight_max is not None else \"No weight data available\")\n",
    "print(f\"Mean: {weight_mean} kg\" if weight_mean is not None else \"No weight data available\")\n",
    "print(f\"Median: {weight_median} kg\" if weight_median is not None else \"No weight data available\")\n",
    "print(f\"Standard Deviation: {weight_std_dev} kg\" if weight_std_dev is not None else \"No weight data available\")\n",
    "print()\n",
    "\n",
    "print(\"Lifespan Statistics:\")\n",
    "print(f\"Min: {lifespan_min} years\" if lifespan_min is not None else \"No lifespan data available\")\n",
    "print(f\"Max: {lifespan_max} years\" if lifespan_max is not None else \"No lifespan data available\")\n",
    "print(f\"Mean: {lifespan_mean} years\" if lifespan_mean is not None else \"No lifespan data available\")\n",
    "print(f\"Median: {lifespan_median} years\" if lifespan_median is not None else \"No lifespan data available\")\n",
    "print(f\"Standard Deviation: {lifespan_std_dev} years\" if lifespan_std_dev is not None else \"No lifespan data available\")\n",
    "print()\n",
    "\n",
    "print(\"Frequency Table of Country and Breed:\")\n",
    "for country, breeds in frequency_table.items():\n",
    "    print(f\"{country}:\")\n",
    "    for breed, count in breeds.items():\n",
    "        print(f\"  {breed}: {count}\")\n",
    "    print()\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Largest Countries by Area:\n",
      "Russia: 17098242.0 sq. km\n",
      "Antarctica: 14000000.0 sq. km\n",
      "Canada: 9984670.0 sq. km\n",
      "China: 9706961.0 sq. km\n",
      "United States: 9372610.0 sq. km\n",
      "Brazil: 8515767.0 sq. km\n",
      "Australia: 7692024.0 sq. km\n",
      "India: 3287590.0 sq. km\n",
      "Argentina: 2780400.0 sq. km\n",
      "Kazakhstan: 2724900.0 sq. km\n",
      "\n",
      "10 Most Spoken Languages:\n",
      "eng: 91 countries\n",
      "fra: 46 countries\n",
      "ara: 25 countries\n",
      "spa: 24 countries\n",
      "por: 10 countries\n",
      "rus: 7 countries\n",
      "nld: 7 countries\n",
      "zho: 5 countries\n",
      "deu: 5 countries\n",
      "ita: 4 countries\n",
      "\n",
      "Total Number of Languages in the Countries API: 155\n"
     ]
    }
   ],
   "source": [
    "# Read the countries API and find\n",
    "# the 10 largest countries\n",
    "# the 10 most spoken languages\n",
    "# the total number of languages in the countries API\n",
    "\n",
    "import requests\n",
    "\n",
    "countries_api = 'https://restcountries.com/v3.1/all'\n",
    "\n",
    "# Fetch data from the Countries API\n",
    "response = requests.get(countries_api)\n",
    "countries_data = response.json()\n",
    "\n",
    "# Extract relevant information\n",
    "countries_info = []\n",
    "\n",
    "for country in countries_data:\n",
    "    name = country.get('name', {}).get('common', 'Unknown')\n",
    "    area = country.get('area', 0)\n",
    "    population = country.get('population', 0)\n",
    "    languages = country.get('languages', [])\n",
    "    \n",
    "    countries_info.append({\n",
    "        'name': name,\n",
    "        'area': area,\n",
    "        'population': population,\n",
    "        'languages': languages\n",
    "    })\n",
    "\n",
    "# Find the 10 largest countries by area\n",
    "largest_countries = sorted(countries_info, key=lambda x: x['area'], reverse=True)[:10]\n",
    "\n",
    "# Find the 10 most spoken languages\n",
    "all_languages = [language for country in countries_info for language in country['languages']]\n",
    "spoken_languages_counts = {language: all_languages.count(language) for language in set(all_languages)}\n",
    "most_spoken_languages = sorted(spoken_languages_counts.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "# Calculate the total number of unique languages\n",
    "unique_languages = set(all_languages)\n",
    "total_languages = len(unique_languages)\n",
    "\n",
    "# Print the results\n",
    "print(\"10 Largest Countries by Area:\")\n",
    "for country in largest_countries:\n",
    "    print(f\"{country['name']}: {country['area']} sq. km\")\n",
    "\n",
    "print(\"\\n10 Most Spoken Languages:\")\n",
    "for language, count in most_spoken_languages:\n",
    "    print(f\"{language}: {count} countries\")\n",
    "\n",
    "print(f\"\\nTotal Number of Languages in the Countries API: {total_languages}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UCI is one of the most common places to get data sets for data science and machine learning. Read the content of UCL (https://archive.ics.uci.edu/ml/datasets.php). Without additional libraries it will be difficult, so you may try it with BeautifulSoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error 404: Not Found\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "from html.parser import HTMLParser\n",
    "\n",
    "class MyHTMLParser(HTMLParser):\n",
    "    def handle_data(self, data):\n",
    "        print(data.strip())\n",
    "\n",
    "uci_url = 'https://archive.ics.uci.edu/ml/datasets.php'  # Update the URL\n",
    "\n",
    "try:\n",
    "    with urllib.request.urlopen(uci_url) as response:\n",
    "        html_content = response.read().decode('utf-8')\n",
    "\n",
    "    parser = MyHTMLParser()\n",
    "    parser.feed(html_content)\n",
    "\n",
    "except urllib.error.HTTPError as e:\n",
    "    print(f\"HTTP Error {e.code}: {e.reason}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
